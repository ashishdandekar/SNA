
\author{
	Ashish Dandekar - A0123873\\
	Debabrota Basu  - A0123893\\\\
	National University of Singapore,\\
	Singapore
}
\date{\today}

\documentclass[12pt]{article}
\usepackage[margin=1.0in]{geometry}
\usepackage{amsmath}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{hyperref}
\usepackage{float}
\usepackage{graphicx}
\usepackage{multirow}
\DeclareMathOperator*{\argmax}{arg\,max}

\begin{document}
\maketitle
\tableofcontents

\section{Introduction}
\par We are surrounded by different kinds of networks and we, as well, are part of many of them. They range from networks as gigantic as WWW, Internet to small networks like friend circle of a single person. Networks, in mathematicians' parlance are nothing but graphs, have been extensively studied since the inception of Graph Theory. Due to their pervasiveness, the study is not only limited to mathematics but also spans subjects as diverse as sociology, economics and needless to state computer science. \\

\par Social Networks are the graphs where the nodes are represented by a set of actors and edges correspond to relation amongst them. The notion of actors and relation is akin to the underlying representation of the social network. For instance citation network is a kind of social network wherein actors are researchers and the relationship can be thought of citations. Actor network, a social network wherein actors are movie stars and relationship between two of them can be thought of as having roles in a common movie. Actor network is represented by a undirected graph unlike citation network which is directed graph. \\

\par Actors in the network are affected by both the topology of the network and the dynamics over the network. These effects have been studied by many researchers spanning many various domains. For example the implications of famous 'small-world' experiment by Stanley Milgram\cite{milgram} piqued the interest among scientist to explore the traits of the social network such as triadic closure, diameter, degree distribution, etc. Starting from purely mathematical model of graph, Random Graph due to Erd\H{o}s-R\'enyi\cite{erdos}, many synthetic models were proposed which imitated the observations from empirical data. Small-world model\cite{watts} proposed by Watts-Strogatz incorporated the existence of small paths, Klienberg's small world model\cite{kleinberg} added the notion of navigation in the network. Scale-free networks, also know as Albert-B\'arabasi model\cite{barabasi}, which closely resemble many real-world networks allow existence of hubs. For the detailed survey of the network models, refer to \cite{newmann}. Dynamical processes such as epidemics, cascades have been studied over various models of the social network. It has been observed that dynamics of these processes is attributed to the underlying properties of the graph\cite{keeling}. \\

\par This report discusses two characteristics of the graph in the context of social network. The report analyses diameter and number of triangles in random network, scale-free network and real-world data. Later, the problem of virus spreading has been studied to check for correlation between dynamics and the attributes of the graph.

\section{Notation}
Mathematically a social network is represented as a graph $G ~=~ (V, E)$ where $V$ denotes the set of vertices and $E$ denotes set of edges. $N$ denotes the total number of nodes in the graph. We will be discussing about the undirected graphs but this applies to directed graphs as well with a few amendments in the definitions. Consider following definitions w.r.t. given graph $G$.
\begin{enumerate}
	\item $d(u, v)$ denotes the distance of the shortest path between nodes $u$ and $v$.
	\item Eccentricity of a node is defined as the length of the maximum shortest path from the node i.e. $ecc(u) ~=~ \argmax_u d(u, v)$
	\item Diameter of a graph is defined to be the maximum value of the eccentricity \\i.e. $D ~=~ \max_{u \in V} ecc(u)$
	\item $k_i$ denotes the degree of the $i^{th}$ vertex.
\end{enumerate}

\section{Network Models}
Social networks stand aside from any arbitrary graphs due to a few characteristics pertinent to them. Before looking at various network models let's look at few of these characteristics which are of more concern to the current study.
\begin{description}
	\item [Small-World Effect]
	\par Although there are huge number of nodes in social network, there do exist paths of comparatively very short length in the network. In a famous experiment of Milgram\cite{milgram}, he showed the median shortest path length in the graph as huge as US population is roughly 6. Later mean path length in various social networks has been empirically calculated, which asserts the observed effect\cite{newmann}. There are a few projects like Erd\H{o}s Number and Bacon Number which are based on the similar idea.
	\par Mathematically this small-world effect is quantified as: Graph $G ~=~ (V, E)$ is said to possess small-world property if $d(u, v) \propto \log(N)$. There are  two kinds of edges one expects in the social network: a strong tie or a weak tie. Strong ties are the one which connect nodes in the vicinity giving rise to clustering  whereas weak ties connect vertices in the distant parts of the graph. These distant ties are responsible for the existence short paths.

	\item [Clustering]
	\par There are two properties which are often observed in the social networks. First one is called {\it homophily}. {\it Homophily} refers to the property of connections between similar nodes. If you think about friendship networks, this property seems patent. We usually befriend with people with whom we share interests. Second property is called {\it triadic closure}. It refers to transitivity or formation of triangles in the network. Again with friendship network analogy, it is highly likely that two friends of a person are friends themselves. Generally, both of these properties go hand in hand giving rise to clusters in the network.
	\par Mathematically clustering is quantified by clustering coefficient. It is defined as:
	\[
		C~=~ \frac {3 * \textrm{number of triangles in the graph}} {\textrm{number of connected triples}}
	\]
	This definition is gives the global clustering of entire graph. Local clustering coefficient\cite{watts} can be defined for a vertex which can further used for determining global clustering coefficient. It can be calculated as:
	\[
		C_i~=~ \frac {\textrm{number of triangles connected to vertex i}} {\textrm{number of triples connected to vertex i}}
	\]
	\[
		C ~=~ \sum_{v \in N}{C_v}
	\]
	As it can be directly seen from the definition of the clustering coefficient, higher the value of clustering coefficient higher the clustering in the graph.

	\item[Degree Distribution]
	\par Degree distribution is as the name suggests profile of the network with respect to the degree of the vertices in the graph. It is the plot of degrees of vertices against the fraction of the vertices having corresponding degree. Degree distribution defines the probability distribution function over the graph. Looking at the plot of degree distribution, we can visualize the various kinds of nodes in the network. The nodes with very large value of degree are called as {\it hubs} while graph may consist of {\it singletons}. We will see the degree distribution of random network and preferential attachment network model.
	\par It has been observed that real-world networks follow power-law degree distribution, namely,
	\[
		P_k ~\propto~ k^{-\gamma}
	\]
	Such networks are known as {\it Scale Free Networks}. We will see that preferential attachment model gives rise to scale free networks. This distribution does not forbid the existence of the nodes with large degrees, which is consistent with what we observe in general(think about friendship network!).

	\item[Miscellaneous]
	\par There are many properties like network resilience, community structure, degree correlations which can be very well be discussed but they are of less importance in the current study. One interesting fact which can not be left unnoticed is the sparsity of the real world networks. Despite the colossal size of web-graph, the density of such networks is really small. Another characteristic is the existence of a giant component in the graph.

\end{description}
Network models are mathematical abstractions which mimic social networks by exhibiting one or more properties listed above. Let's look at two popular network models, one which is mathematically elegant but fails to resemble real-world networks and the other one which does resemble to real-world networks.

\subsection{Random Graphs}
Random graph is the very first kind of network model to be developed and studied. These models were studied independently by Erd\H{o}s-R\'enyi\cite{erdos} and Gilbert\cite{gilbert}. There are two random graph models in literature.
\begin{enumerate}
	\item $G_{N,p}$ In this model, graph $G$ consists of $N$ nodes. Edge is added between a pair of nodes with probability $p$
	\item $G_{N,m}$ In this model, graph $G$ consists of $N$ nodes. $m$ edges are added to randomly selected node pairs.
\end{enumerate}
We will consider the first model. Let's look at properties of this model.

\subsubsection{Degree Distribution}
Consider $G_{N,p}$ model where $p$ denotes the probability of existence of an edge. Probability of getting exactly $L$ edges, $P_L$, is nothing but the same Bernoulli experiment done $L$ times. Hence, $P_L$ follows Binomial Distribution given by:
\[
P_L ~=~ {{N \choose 2} \choose L}p^L(1 - p)^{{N \choose 2} - L}
\]
Mean number of edges is given by: 
\begin{align*}
<L> ~&=~ {N \choose 2}p \\
	 &=~ \frac{N(N - 1)}{2}p
\end{align*}
Recalling that:
\[
<k> ~=~ \frac{2 ~*~<L>}{N}
\]
We get,
\[
<k> ~=~ (N - 1)p
\]
Looking at the average degree, thinking in the reverse way, we can think of $P_k$ Binomial degree distribution for $G_{N, p}$ with parameter $p$. Thus degree distribution for $G_{N,p}$ is given by:
\begin{equation}
P_k ~=~ {N - 1 \choose k}p^k(1 - p)^{N - 1 - k}
\end{equation}
As stated in the properties of the social networks, the real-networks are really sparse. This clearly implies that $<k> ~\ll N$. By invoking Binomial approximation to Poisson distribution, $P_k$ follows Poisson Distribution with parameter $<k>$.
\begin{equation}
P_k ~=~ e^{-<k>} \frac {<k>^k} {k!}
\end{equation}
Looking at the degree distribution, we can infer the nature of nodes we have in the graph. Being a Poisson distribution, we can say that large fraction of the population has degree close to $<k>$. Rapid fall of Poisson for large values of $k$ implies that it is highly unlikely to have nodes with very large degree.

\subsubsection{Diameter}
\par As defined earlier, diameter of the network is the longest geodesic distance between two nodes in the graph. Generally, this diameter is overestimated by the outliers and hence many a times diameter is taken to be the average geodesic path. With this weak assumption, let's calculate the diameter of the random graph.
\par A random graph with mean degree $<k>$ has $<k>$ neighbours at the first hop in expectation, $<k>^2$ neighbours at the second hop and so on. Therefore, expected number of nodes at $d^{th}$ hop is given by:
\begin{align*}
N_d &= 1 ~+~ <k> ~+~ <k>^2 ~+~ ... ~+~ <k>^d \\
	&= \frac {<k>^{d + 1} - 1} {<k> - 1} \\
	&\approx <k>^d	&& \text{for large graphs $<k> ~\gg 1$}
\end{align*}
Let, $D$ be the maximum $d$ which nearly covers all the graph. (There exists a value of $p$ close to $\frac{1}{N}$ for which graph becomes connected). Plugging this in above equation,
\[
N \approx <k>^{D}
\]
\begin{equation}
D \propto \frac {\log N} {\log <k>}
\end{equation}
Thus on average random network has paths of short length i.e. proportional to $\log N$. For strong analysis of the problem please refer to \cite{chung_diameter}

\subsubsection{Triangles}
Random network is constructed by adding random edges in the network. While constructing network, there is no bias towards formation of triangles which makes finding triangles a totally probabilistic event. There are $N \choose 3$ possible triples in the graph and $p$ is the probability of having a single edge between two vertices. Hence,
\begin{equation}
\#\text{triangles} ~=~ {N \choose 3}p^3
\end{equation}

\subsection{Scale Free Networks}
Growth and preferential attachment are the two key features which are necessary to get a scale free network. Preferential attachment procedure for the evolution of the network outlined in \cite{barabasi} gives rise to scale free network. The procedure is given below:
\begin{description}
	\item [Growing Step] Start with small number of $m_0$ nodes. At every time-step add a new node with $m < m_0$ edges to the network.
	\item [Preferential Attachment] The probability of attaching a new node to existing node $i$ is proportional to the degree of $i$ i.e.
\[
	\Pi(k_i) ~=~ \frac {k_i} {\sum_{j} {k_j}}
\]
\end{description}
The index $j$ in the denominator runs over all the vertices present at the time-step of the above calculation. In this case study, we will see a variant of this model wherein we will start with single vertex and add an edge between a new vertex and an old vertex at every time-step. For some $p \in [0,1]$ old vertex $i$ is chosen with probability given by
\[
	\Pi(k_i) ~=~ \frac {p ~*~ k_i} {\sum_{j} {k_j}}
\]

\subsubsection{Degree Distribution}
As the graph evolves with time, the degree of a vertex is a function of time. Assuming the degree of vertex lies in the continuous domain, we can write differential equation signifying rate of change of degree at each time-step. As a node $i$ receives at most a single edge every time-step, we can write
\begin{align*}
\frac {dk_i} {dt} &~=~ \frac {p k_i} {\sum_{j} {k_j}} \\
	&~=~ \frac {p k_i} {2t}
\end{align*}
Last step is achieved using the Handshaking lemma $\sum_{v \in V}{k_i} ~=~ 2|E|$. In this model, a single edge is added at every time-step. Hence at time $t$, there are $t$ edges in the graph. Solving above differential equation and using initial condition that node $i$, added at time $t_i$, has degree 1, we get
\[
k_i ~=~ \left(\frac {t} {t_i}\right)^{\frac {p} {2}}
\]
Now we have got the random variable for each vertex. The traditional procedure to get the distribution function is to calculate cumulative distribution function and later differentiate it to get the distribution function. Let's follow the same procedure:
\begin{align*}
F(k) &= Pr(k_i(t) < k) \\
	 &= Pr(t_i > \frac {t} {k^{2/p}})
\end{align*}
As we add a edge every time, we have: $Pr(t_i) ~=~ \frac {1} {1 + t}$ which is a uniform probability distribution. As edges are independently added to the graph, $Pr(t_i < t) = \frac {t} {1 + t}$. Using this we get,
\[
F(k) ~=~ 1 ~-~ \frac {t} {k^{2/p}(1 + t)}
\]
Degree distribution is given by:
\begin{align}
P_k &=\frac {dF(k)} {dk} \nonumber \\
	&=\frac {2t} {(t + 1)p} k^{-(1 + \frac{2}{p})}
\end{align}
Thus above preferential attachment procedure given above generates a scale free network with degree exponent $\gamma ~=~ 1 + 2/p$. From $t = 1$ onwards by adding an edge at every time-step we are increasing degree of the chosen vertex by one. Thus average degree of the graph obtained by this procedure must be approximately $2$.

\subsubsection{Diameter}
Albert et.al. \cite{statistical}, using the empirical data observed that the average path length in the scale free network is proportional to $\log N$. They observed for any given $N$ this distance is always less than that of random network of size $N$. Later Bollob\'as\cite{bollobas} gave rigorous mathematical result giving the diameter of the scale free network. For a network constructed by adding an edge at a time, the diameter of the network is still proportional to $\log N$. But for the networks generated by adding more than an edge at a time-step, the diameter asymptotically equals to $\frac {\log N} {\log \log N}$.

\subsubsection{Triangles}
There is no direct closed form result which gives the number of triangles in the graph. In \cite{bollobas_triangles}, Bollob\'as has given a theorem which states that in a preferential attachment network with $N$ vertices, one can give model which will have $\log N$ or $N^{\alpha} \text{ for} \alpha \in [0, 1]$ triangles.

\section{Algorithms}
\subsection{Diameter}
By looking at the definition of the diameter, it seems to be the obvious task. What we want to do is to calculate All Pair Shortest path, for which we have algorithms like Floyd-Warshall running in polynomial time($\mathcal{O}(n^3)$), and find the maximum distance shortest path. But with the gigantic social networks, this naive approach is prohibitive. So we must resort to other approaches for the calculation. In literature three different kinds of ways to tackle this problem have been observed.
\begin{description}
	\item[Parallel and Distributed Platforms]
	With increasing availability of high performance cloud resources and distributed computer frameworks like Hadoop, large number of parallel algorithms have been developed for solving the computationally costly problems. Kang et.al.\cite{HADI} have developed algorithm, {\it HADI}, on top of Hadoop framework. They have performed rigorous tests on the graphs as huge as the one having billions of nodes and edges.
	\item[Approximation Algorithm and Bounds]
	Aingworth et.al.\cite{aingworth} were the first to give a 3/2-approximation algorithm to find diameter of the graph in $\mathcal{O}(m\sqrt{n\log n} + n^2 \log n)$ time. Recently Roditty et.al.\cite{roditty} improved the algorithm running time to $\mathcal{O}(n^2)$. Apart from these approximations, another approach is to get upper and lower bounds for the diameter of the graph and later devise algorithms to get tighter bounds. Magnien et.al.\cite{magnien} have given few very naive upper and lower bounds for the diameter of the graph. The results have shown that {\it double sweep lower bound} for the diameter gives the lower bound which is pretty close to the optimal diameter of the graph. Crescenzi et.al.\cite{crescenzi} later gave algorithm using the heuristics of the bounds to get tighter bounds for the diameter. We will later see this approach.
	\item[Alternative Definitions]
	As stated earlier in Section 2, the definition of the diameter of the graph is prone to outliers in the set of geodesic distances. Many a times, average geodesic distance is taken to be the diameter of the graph. Lekovec\cite{leskovec} defines {\it effective diameter} of the network to be the minimum number of hops required so that $90\%$ of the node pairs can reach each other. HADI algorithm can as well be used to find {\it effective diameter} of the graph.
\end{description}
We have implemented the fringe algorithm given by Crescenzi. Algorithm \ref{fringe} outlines the pseudocode. Algorithm assumes that $G$ is a connected graph. If the graph is not connected, the algorithm returns the diameter for the connected part of the graph to which $r$ belongs. Name refers to the vertices at the fringe i.e. farthest distance from a given vertex.
\par Fringe algorithm initially randomly chooses a vertex from the graph and finds eccentricity for it. Then it chooses any vertex at the fringe of the initial vertex and finds eccentricity for it. This is a double sweep lower bound given by \cite{magnien}. To get more close to the actual diameter, algorithm chooses a vertex as a seed which is midway between the second vertex and a vertex at the fringe of it. BFS is done on this seed vertex to find its eccentricity and the set of vertices at its fringe, $F_u$. This set along with eccentricities of the vertices in the set are used to approximate the diameter of the graph. Thus, this algorithm take $|F_u| + 3$ BFS searches and hence $\Theta((|F_u| + 3)m)$ time.
\begin{algorithm}[H]
\caption{Fringe Algorithm}\label{fringe}
\begin{algorithmic}
\Procedure{FindDiameterUpperBound}{G}
\State $r \gets \text{random node from the graph}$
\State $a \gets \argmax_v d(r, v)$
\State $b \gets \argmax_v d(a, v)$
\State $u \gets \text{a node which is midway on path a-b}$
\State $T_u \gets \text{BFS tree initiated from u}$
\State $F_u \gets \{v | argmax_v ~d(u, v)\}$ \Comment{These are the nodes which are at fringe of the tree}
\If {$|F_u| = 1$}
\State \Return {ecc(u)}
\Else
\State $B_u \gets \max_{v \in F_u} ecc(v)$
\If {$B_u == 2ecc(u) - 1$}
\State \Return $B_u$
\Else{$~~$} 
\Return $2ecc(u) - 2$
\EndIf
\EndIf
\EndProcedure
\end{algorithmic}
\end{algorithm}

\subsection{Triangles}
A naive way to find the triangles in the graph is to iterate over all possible triples of the edges and for each triple check if the triple forms a triangle. This approach is not bad unless you have a massive graph. This strategy requires $\mathcal{O}(m^3)$ time which makes it impractical for huge graphs.
\par One can think of {\it linear algebraic} way to count the number of triangles. Given the adjacency matrix representation $\mathbf{A}$ of the graph, consider the powers of the matrix. $[\mathbf{A}^k]_{ij}$ entry denotes the number of paths of $k$ length from vertex $i$ to $j$. Hence, sum of the diagonal entries in the matrix $\mathbf{A}^3$ counts the number of triangles in the graph. For large graph, even this calculation is prohibitive. For undirected graph, corresponding adjacency matrix is symmetric which ensures eigen-decomposition. Then one can use efficient iterative method like {\it Lanczos Algorithm} to calculate top eigenvalues which can be cubed to get the number of triangles\cite{eigen}. To get a good approximation, one needs to get many eigenvalues(considering the size of the graph N) which again hinders its application on massive graphs.
\par In both the methods mentioned above, the size of the graph seems to be the bottleneck. What if we sample the graph and work on small sample and scale the result to get answer the original problem? Consider a simple random sampling method. Flip a biased/unbiased coin(with probability of getting head, say $p$). With probability $p$, remove the edge from the graph. In this way, for each edge in the graph flip the coin and get a new sampled graph. Using the same approach, eigenvalue based triangle counting was later improved\cite{improved_eigen}.
\par In this study, we have implemented {\it DOULION}\cite{doulion} algorithm which uses the same random sampling idea described above. After getting the sampled graph, run the naive algorithm to count the number of triangles in the sampled version. This process can be thought of assigning weights to the edges in the graph. The edges which survive get $1 / p$ weight each, whereas the edges that do not survive get $0$ weight. Each triangle is counted as ${\frac {1}{p}}^3$. Algorithm \ref{doulion} delineates the pseudocode for the algorithm.
\begin{algorithm}[H]
\caption{DOULION Algorithm}\label{doulion}
\begin{algorithmic}
\Procedure{Sparsify}{G, p}
\For {$e \in E$}
\State Flip a coin and with probability p remove the edge e
\EndFor
\EndProcedure

\Procedure{FindNumberOfTriangles}{G, p}
\State $SPARSIFY(G, p)$
\State $count \gets 0$
\For {$(u, v, w) \in E \times E \times E$}
\If {$(u, v, w)$ forms a triangle}
\State $count = count + 1$
\EndIf
\EndFor \\
\Return $count / p^3$
\EndProcedure
\end{algorithmic}
\end{algorithm}

\section{Epidemics and Rumours}
Study of epidemics has been the part of sociology since a long time. The term {\it epidemic} in Social Network Analysis may refer to spread of any kind of information ranging from diseases, viruses to ideas, fads, etc. Classical epidemic theory uses differential equations to find the rate of spread of diseases. The abstraction of society as a social network opens a whole new spectrum of interpretations of graph properties to qualitatively analyse the epidemics in society\cite{keeling}. It can be observed that the nature of epidemic is pertinent to the kind of information being spread on the network. For example in case of ideas or fads, before pervasive spread occurs network has to have sufficient amount of nodes bearing the information. Whereas in case of diseases you don't have such a restriction. If you think about spread of computer viruses, adversaries have motives(may that be ill motive!) for spreading the virus. So, we can not use graph theory alone to solve such problems. Generally problems where each node has strategies are studied in economics in conjunction with game theory.
\par Essence of the above discussion is that study of epidemics in social networks not only depends on the kind of information but also on the kind of roles played by the nodes in the network. In this study, we will be studying spread of viruses in the social network wherein the nodes in the network don't have any strategy. There are various models to simulate epidemics on the social network\cite{crowds}. Few of them are listed below:
\begin{description}
	\item[SIR Model]
	SIR stands for Susceptible-Infected-Recovered. In this model, there are a few nodes(even one node is allowed) which have been infected in the beginning. All the remaining nodes are susceptible to the disease. As time passes, infected nodes pass on the disease to their neighbours turning them into infected nodes. There is a recovery time for the disease after which infected nodes get recovered and they are assumed to get lifetime immunity from the disease. After recovery, the recovered nodes will not be able to transmit the disease to their neighbours.
	\item[SIRS Model]
	It is not necessary that the immunity of a node, after being recovered, lasts for the lifetime. Diseases like flu do not give lifetime immunity to the person. SIRS model is logical extension of the SIR model. In the SIR model, recovered nodes are removed from the network. On the other hand, in SIRS model, there is some finite amount of time after which a recovered node becomes again susceptible to the disease.
\end{description}
\par Along the parallel lines, study of spreading the rumor is of essence in the area of distributed computing. The idea of spreading the rumours is formalized by {\it push/pull} algorithms. In {\it push} algorithm, a node with information to share, sends it to a randomly chosen neighbour. On the other hand, in {\it pull} algorithm at every timestep, a node without any information pulls information(if available!) from randomly chosen neighbour. It has been show that both of these strategies are not good in the long run but they are much better when used in unison.
\par In this study, a {\it push} algorithm is impemented for spreading the rumour over the network. In this variant, initially we have a single node with some information. Later it passes on the rumour to one of its randomly selected neighbours. Comparing this with standard SIR model, it is the one with infinite recovery time. At each step fraction of infected population is calculated.


\section{Experiments}
The network models are implemented in {\it Python} using the {\it NetworkX} package which provides user friendly API for graph primitives. Algorithms for calculating diameter and counting number of triangles were also implemented in {\it Python}. The programs were run on a doubly Hyperthreaded dual core Intel\textsuperscript{\textregistered} Core i3-2310M CPU with 3.8GB of RAM and Linux based OS. Let's discuss various observations one by one. {\it YouTube social network} dataset from SNAP\cite{snap} has been used for testing against huge real social network. This graph consists of $1,134,890$ nodes and $2,987,624$ edges.
\subsection{Degree Distribution}
The degree distribution plots for Random Graphs and PA model discussed in Section 2 are shown in Table \ref{degree}. Each graphs consists of 1000 nodes and tuned by parameter $p$. For plotting purposes, $matplotlib$ in $python$ is used.
\par In case of Random Graphs, at very small values of $p$, graph consisted of many singleton nodes and a few small connected components and hence the Poisson distribution is not prominent in that region. In Random Graphs, a giant component emerges when $p$ crosses $1/N$ in our case it is $0.001$. For probabilities greater than $0.001$, Poission distribution is manifest.
\par In case of PA graphs, power law can be seen. Since there are many vertices with small degree with a few with large degrees, natural value plots are not convenient for visualization. Third column in the table show the corresponding log-log plot of the degree distribution. One can clearly see the linear fit for the points. Using slope of this linear fit as the power law exponent can be fallacious. The issue of calculating the degree exponent is discussed thoroughly in \cite{pareto}.

\begin{table}[H]
\centering
\begin{tabular}{l|l}
\hline
\includegraphics[width=2.0in, height=2.0in]{images/youtube_normal.png} & \includegraphics[width=2.0in, height=2.0in]{images/youtube_loglog.png} \\ \hline
\end{tabular}
\caption{Degree Distribution for {\it YouTube Social Network}}
\label{youtube_degree}
\end{table}

\begin{table}[H]
\centering
\begin{tabular}{|c|l|l|l|}
\hline
\multicolumn{1}{|l|}{p} & \multicolumn{1}{c|}{Random Graph} & \multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}PA\\ (Normal Plot)\end{tabular}} & \multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}PA\\ (log-log plot)\end{tabular}} \\ \hline
0.0004 & \includegraphics[width=1.5in, height=1.5in]{images/RG_1.png} & \includegraphics[width=1.5in, height=1.5in]{images/PA1_1.png} & \includegraphics[width=1.5in, height=1.5in]{images/PA2_1.png} \\ \hline
0.0008 & \includegraphics[width=1.5in, height=1.5in]{images/RG_2.png} & \includegraphics[width=1.5in, height=1.5in]{images/PA1_2.png} & \includegraphics[width=1.5in, height=1.5in]{images/PA2_2.png} \\ \hline
0.001 & \includegraphics[width=1.5in, height=1.5in]{images/RG_3.png} & \includegraphics[width=1.5in, height=1.5in]{images/PA1_3.png} & \includegraphics[width=1.5in, height=1.5in]{images/PA2_3.png} \\  \hline
0.008 & \includegraphics[width=1.5in, height=1.5in]{images/RG_4.png} & \includegraphics[width=1.5in, height=1.5in]{images/PA1_4.png} & \includegraphics[width=1.5in, height=1.5in]{images/PA2_4.png} \\  \hline
0.01 & \includegraphics[width=1.5in, height=1.5in]{images/RG_5.png} & \includegraphics[width=1.5in, height=1.5in]{images/PA1_5.png} & \includegraphics[width=1.5in, height=1.5in]{images/PA2_5.png} \\ \hline
\end{tabular}
\caption{Degree Distribution}
\label{degree}
\end{table}
\par Table \ref{youtube_degree} shows the degree distribution plot for the {\it YouTube social Network}. It cleasrly shows the scale-free nature of the distribution.


\subsection{Diameter and Triangle Counting}
Readings for this section were taken by taking mean over $5$ runs. The results are shown in the Table \ref{diameter}. The sparsification parameter for the {\it DOULION} algorithm was set to $0.5$.The last column shows the diameter and triangles for the B\'arabasi-Albert model, generally written as BA model, with $m = 4$ i.e. adding four edges at each iteration. The PA model discussed in the Section 2, adds a single node with single edge at every iteration. Hence, the resultant graph turns out to be a tree. So, to get a better idea about the PA graphs these experiments were perormed.
\par In Random Graph, for small values of $p$, triangles are absent. This can be reasoned by looking at the degree sistribution. The {\it tree} nature of the PA model in Section 2 can be validated by absence of triangles in the graph.
\par As mentioned earlier, for small values of $p$ Random graph is disconnected. The diameter noted in the table is that of giant component in the network. $\mathcal{O}(\log n)$ behaviour. In case of BA model, a new node attaches itself to four old nodes with preferential attachment. This increases the number of triangles in the network. It also tend to reduce the distance between vertices.
\par Number of triangles and the diameter for {\it YouTube Social Network} is given in Table \ref{youtube_dia}

\begin{table}[H]
\centering
\begin{tabular}{|l|c|l|c|c|c|c|}
\hline
\multirow{2}{*}{p} & \multicolumn{2}{c|}{Random Graph} & \multicolumn{2}{c|}{Preferential Attachment (m = 1)} & \multicolumn{2}{c|}{Preferential Attachment (m = 4)} \\ \cline{2-7} 
 & Triangles & \multicolumn{1}{c|}{Diameter} & Triangles & Diameter & Triangles & Diameter \\ \hline
0.0004 & 0 & \multicolumn{1}{c|}{6} & 0 & 15 & \multirow{5}{*}{\begin{tabular}[c]{@{}c@{}}272\\ (average over\\ 5 runs)\end{tabular}} & \multirow{5}{*}{\begin{tabular}[c]{@{}c@{}}6\\ (average over\\ 5 runs)\end{tabular}} \\
0.0008 & 0 & \multicolumn{1}{c|}{9} & 0 & 15 &  &  \\
0.001 & 0 & \multicolumn{1}{c|}{15} & 0 & 15 &  &  \\
0.008 & 8 & \multicolumn{1}{c|}{8} & 0 & 16 &  &  \\
0.01 & 6  & \multicolumn{1}{c|}{8} & 0 & 15 &  & \\ \hline
\end{tabular}
\caption{Trianglesand Diameter in the Graph}
\label{diameter}
\end{table}

\begin{table}[H]
\centering
\begin{tabular}{|c|c|c|}
\hline
\multicolumn{1}{|l|}{} & Result from Implementation & Values in SNAP \\ \hline
\#Triangles &  3.045 Billion & 3.056 Billion \\
Diameter & 18 $\pm$ 4 & 20 \\ \hline
\end{tabular}
\caption{Triangles and Diameter in {\it Youtube Social Network}}
\label{youtube_dia}
\end{table}

%
%\section{Conclusions}
%
\newpage
\bibliographystyle{abbrv}
\bibliography{main}
%
\end{document}
